<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI Research Assistant - Full RAG System</title>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
  <script type="module" src="https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2"></script>
  <script type="module" src="https://cdn.jsdelivr.net/npm/@mlc-ai/web-llm@0.2.46/lib/index.min.js"></script>
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" />
  <style>
    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }
    .spinner {
      border: 3px solid #f3f3f3;
      border-top: 3px solid #667eea;
      border-radius: 50%;
      width: 40px;
      height: 40px;
      animation: spin 1s linear infinite;
    }
    .chat-message {
      animation: slideIn 0.3s ease-out;
    }
    @keyframes slideIn {
      from { opacity: 0; transform: translateY(10px); }
      to { opacity: 1; transform: translateY(0); }
    }
    .citation-badge {
      display: inline-block;
      padding: 2px 8px;
      border-radius: 12px;
      font-size: 0.75rem;
      margin: 2px;
      cursor: pointer;
      transition: all 0.2s;
    }
    .citation-badge:hover { transform: scale(1.1); }
    
    .file-item {
      transition: all 0.2s;
    }
    .file-item:hover {
      background-color: rgba(255, 255, 255, 0.2);
    }

    /* Custom Range Slider */
    input[type=range] {
      height: 6px;
      background: #e0e7ff;
      border-radius: 5px;
      background-image: linear-gradient(#4f46e5, #4f46e5);
      background-size: 0% 100%;
      background-repeat: no-repeat;
    }
    
    input[type=range]::-webkit-slider-thumb {
      -webkit-appearance: none;
      height: 16px;
      width: 16px;
      border-radius: 50%;
      background: #4f46e5;
      cursor: pointer;
      box-shadow: 0 0 2px 0 #555;
    }
  </style>
</head>
<body class="bg-gradient-to-br from-indigo-500 via-purple-500 to-pink-500 min-h-screen">
  <div class="container mx-auto px-4 py-6 max-w-7xl">
    <div class="text-center mb-6">
      <h1 class="text-4xl font-bold text-white mb-2">üìö AI Research Assistant</h1>
      <div class="mt-3 flex justify-center gap-3">
        <span id="embeddingStatus" class="px-4 py-2 rounded-full text-sm font-semibold bg-yellow-400 text-gray-900">
          Loading Embeddings...
        </span>
        <span id="llmStatus" class="px-4 py-2 rounded-full text-sm font-semibold bg-yellow-400 text-gray-900">
          Loading LLM...
        </span>
      </div>
    </div>

    <div class="grid grid-cols-1 lg:grid-cols-3 gap-6">
      <div class="lg:col-span-1 space-y-6">
        
        <div class="bg-white rounded-xl shadow-2xl p-6">
          <h2 class="text-xl font-bold text-gray-800 mb-4 border-b-2 border-indigo-500 pb-2">
            ‚öôÔ∏è System Controls
          </h2>
          
          <div class="space-y-4">
            <div>
              <label class="block text-sm font-medium text-gray-700 mb-1">AI Model</label>
              <select id="modelSelect" class="w-full bg-gray-50 border border-gray-300 text-gray-900 text-sm rounded-lg focus:ring-indigo-500 focus:border-indigo-500 block p-2.5">
                <option value="Phi-3-mini-4k-instruct-q4f16_1-MLC" selected>Phi-3 Mini (Balanced)</option>
                <option value="Llama-3-8B-Instruct-q4f16_1-MLC">Llama-3 8B (Smarter/Slower)</option>
                <option value="TinyLlama-1.1B-Chat-v1.0-q4f16_1-MLC">TinyLlama (Fastest/Weak)</option>
              </select>
              <p class="text-xs text-gray-500 mt-1">Changing models triggers a new download.</p>
            </div>

            <div>
              <div class="flex justify-between items-center mb-1">
                <label class="block text-sm font-medium text-gray-700">Temperature</label>
                <span id="tempValue" class="text-sm font-bold text-indigo-600">0.3</span>
              </div>
              <input type="range" id="tempSlider" min="0" max="1" step="0.1" value="0.3" class="w-full h-2 bg-gray-200 rounded-lg appearance-none cursor-pointer">
              <div class="flex justify-between text-xs text-gray-400 mt-1">
                <span>Precise</span>
                <span>Creative</span>
              </div>
            </div>

            <div>
              <label class="block text-sm font-medium text-gray-700 mb-1">Max Tokens (Response Length)</label>
              <input type="number" id="tokenInput" value="1024" min="128" max="4096" step="128" class="w-full bg-gray-50 border border-gray-300 text-gray-900 text-sm rounded-lg focus:ring-indigo-500 focus:border-indigo-500 block p-2.5">
            </div>
          </div>
        </div>

        <div class="bg-white rounded-xl shadow-2xl p-6">
          <h2 class="text-xl font-bold text-gray-800 mb-4 border-b-2 border-indigo-500 pb-2">
            üìÑ Document Ingestion
          </h2>
          
          <div id="dropZone" class="border-3 border-dashed border-indigo-400 rounded-lg p-8 text-center cursor-pointer hover:bg-indigo-50 transition-all">
            <div class="text-5xl mb-3">üìÑ</div>
            <div class="text-indigo-600 font-semibold mb-2">Drop PDFs here or click</div>
            <div class="text-gray-500 text-sm">Supports multiple files</div>
          </div>
          <input type="file" id="fileInput" class="hidden" accept=".pdf" multiple>

          <div id="processingStatus" class="mt-4"></div>
        </div>

        <div class="bg-white rounded-xl shadow-2xl p-6">
          <div class="flex justify-between items-center mb-4 border-b-2 border-indigo-500 pb-2">
            <h2 class="text-xl font-bold text-gray-800">üíæ Memory Bank</h2>
            <span id="totalVectors" class="text-xs font-mono bg-gray-200 text-gray-700 px-2 py-1 rounded">0 Vectors</span>
          </div>
          
          <div id="memoryBank" class="bg-gradient-to-br from-indigo-600 to-purple-700 text-white p-4 rounded-lg min-h-[150px]">
            <div class="text-center opacity-80 text-sm italic mt-8">No documents loaded</div>
          </div>
          
          <button id="clearBtn" class="w-full mt-4 bg-red-500 hover:bg-red-600 text-white font-semibold py-2 px-4 rounded-lg transition-colors text-sm">
            Delete All Documents
          </button>
        </div>
      </div>

      <div class="lg:col-span-2">
        <div class="bg-white rounded-xl shadow-2xl h-[calc(100vh-100px)] flex flex-col">
          <div class="bg-gradient-to-r from-indigo-600 to-purple-600 text-white p-4 rounded-t-xl flex justify-between items-center">
            <div>
              <h2 class="text-xl font-bold">üí¨ Chat with Your Documents</h2>
              <p class="text-sm opacity-90" id="currentModelDisplay">Model: Phi-3 Mini (High Accuracy)</p>
            </div>
            <button id="exportChat" class="text-white hover:text-indigo-200" title="Export Chat">
              <i class="fas fa-download"></i>
            </button>
          </div>

          <div id="chatContainer" class="flex-1 overflow-y-auto p-6 space-y-4 bg-gray-50">
            <div class="text-center text-gray-500 py-8">
              <div class="text-4xl mb-2">ü§ñ</div>
              <p>Upload PDFs and start chatting!</p>
              <p class="text-xs mt-2 text-gray-400">Note: The first message might take a moment to load the model.</p>
            </div>
          </div>

          <div class="border-t border-gray-200 p-4 bg-white rounded-b-xl">
            <div class="flex gap-3">
              <input 
                type="text" 
                id="chatInput" 
                placeholder="Ask a question about your documents..." 
                class="flex-1 px-4 py-3 border-2 border-gray-300 rounded-lg focus:border-indigo-500 focus:outline-none"
                disabled
              >
              <button 
                id="sendBtn" 
                class="bg-indigo-600 hover:bg-indigo-700 text-white font-semibold px-6 py-3 rounded-lg transition-colors disabled:bg-gray-300 disabled:cursor-not-allowed"
                disabled
              >
                Send
              </button>
            </div>
            <div class="mt-2 text-xs text-gray-500 text-center" id="inputHint">
              Waiting for models to load...
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <script type="module">
    // ============================================
    // PDF Processor Module
    // ============================================
    const PDFProcessor = (() => {
      pdfjsLib.GlobalWorkerOptions.workerSrc = 
        'https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.worker.min.js';

      async function extractTextFromPDF(file) {
        const arrayBuffer = await file.arrayBuffer();
        const pdf = await pdfjsLib.getDocument({ data: arrayBuffer }).promise;
        let fullText = '';
        for (let i = 1; i <= pdf.numPages; i++) {
          const page = await pdf.getPage(i);
          const textContent = await page.getTextContent();
          const pageText = textContent.items.map(item => item.str).join(' ');
          fullText += pageText + '\n';
        }
        return fullText;
      }

      function recursiveChunkText(text, chunkSize = 800, overlap = 100) {
        const chunks = [];
        text = text.replace(/\s+/g, ' ').trim();
        let start = 0;
        while (start < text.length) {
          let end = start + chunkSize;
          if (end >= text.length) {
            chunks.push(text.slice(start));
            break;
          }
          let breakPoint = -1;
          const lookBack = 200; 
          const slice = text.slice(Math.max(start, end - lookBack), end);
          const lastPeriod = slice.lastIndexOf('. ');
          if (lastPeriod !== -1) {
            breakPoint = Math.max(start, end - lookBack) + lastPeriod + 1;
          } else {
            const lastSpace = slice.lastIndexOf(' ');
            if (lastSpace !== -1) breakPoint = Math.max(start, end - lookBack) + lastSpace;
            else breakPoint = end;
          }
          chunks.push(text.slice(start, breakPoint).trim());
          start = breakPoint - overlap; 
        }
        return chunks.filter(c => c.length > 50); 
      }

      async function processFile(file) {
        const text = await extractTextFromPDF(file);
        const chunks = recursiveChunkText(text);
        return {
          name: file.name,
          size: file.size,
          chunks: chunks,
          charCount: text.length,
          chunkCount: chunks.length
        };
      }

      return { processFile };
    })();

    // ============================================
    // Embeddings Engine Module
    // ============================================
    const EmbeddingsEngine = (() => {
      let pipeline = null;
      let isReady = false;

      async function initialize() {
        try {
          console.log('üîÑ Loading embedding model...');
          const { pipeline: pipelineFn } = await import('https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2');
          pipeline = await pipelineFn('feature-extraction', 'Xenova/all-MiniLM-L6-v2');
          isReady = true;
          console.log('‚úÖ Embedding model ready');
          return true;
        } catch (error) {
          console.error('‚ùå Embedding model failed:', error);
          throw error;
        }
      }

      async function generateEmbedding(text) {
        if (!isReady) throw new Error('Embeddings not ready');
        const output = await pipeline(text, { pooling: 'mean', normalize: true });
        return Array.from(output.data);
      }

      async function generateBatchEmbeddings(texts, onProgress) {
        const embeddings = [];
        for (let i = 0; i < texts.length; i++) {
          embeddings.push(await generateEmbedding(texts[i]));
          if (onProgress) onProgress(i + 1, texts.length);
        }
        return embeddings;
      }

      return { initialize, generateEmbedding, generateBatchEmbeddings };
    })();

    // ============================================
    // Vector Store Module
    // ============================================
    const VectorStore = (() => {
      let store = [];

      function cosineSimilarity(vecA, vecB) {
        let dotProduct = 0, normA = 0, normB = 0;
        for (let i = 0; i < vecA.length; i++) {
          dotProduct += vecA[i] * vecB[i];
          normA += vecA[i] * vecA[i];
          normB += vecB[i] * vecB[i];
        }
        const denominator = Math.sqrt(normA) * Math.sqrt(normB);
        return denominator === 0 ? 0 : dotProduct / denominator;
      }

      function addVectors(entries) {
        entries.forEach(entry => {
          store.push({
            id: Date.now() + Math.random(),
            text: entry.text,
            embedding: entry.embedding,
            source: entry.source,
            timestamp: new Date().toISOString()
          });
        });
      }

      function removeVectorsBySource(sourceName) {
        store = store.filter(item => item.source !== sourceName);
      }

      async function search(queryEmbedding, topK = 5) {
        if (store.length === 0) return [];
        const results = store.map(item => ({
          ...item,
          similarity: cosineSimilarity(queryEmbedding, item.embedding)
        }));
        results.sort((a, b) => b.similarity - a.similarity);
        return results.slice(0, topK);
      }

      function clear() { store = []; }
      function getStats() {
        return {
          count: store.length,
          sources: [...new Set(store.map(item => item.source))]
        };
      }

      return { addVectors, removeVectorsBySource, search, clear, getStats };
    })();

    // ============================================
    // LLM Engine Module (Dynamic Config)
    // ============================================
    const LLMEngine = (() => {
      let engine = null;
      let isReady = false;
      let currentModelId = "Phi-3-mini-4k-instruct-q4f16_1-MLC";
      
      // Default Config
      let config = {
        temperature: 0.3,
        max_tokens: 1024,
        top_p: 0.7
      };

      async function initialize(modelId, onProgress) {
        try {
          isReady = false;
          currentModelId = modelId || currentModelId;
          console.log(`üîÑ Loading LLM: ${currentModelId}...`);
          
          const { CreateMLCEngine } = await import('https://cdn.jsdelivr.net/npm/@mlc-ai/web-llm@0.2.46/lib/index.min.js');
          
          // Re-create engine with new model
          engine = await CreateMLCEngine(
            currentModelId, 
            {
              initProgressCallback: (progress) => {
                if (onProgress) onProgress(progress);
              }
            }
          );
          
          isReady = true;
          console.log('‚úÖ LLM ready');
          return true;
        } catch (error) {
          console.error('‚ùå LLM loading failed:', error);
          throw error;
        }
      }

      function updateConfig(newConfig) {
        config = { ...config, ...newConfig };
        console.log("‚öôÔ∏è LLM Config updated:", config);
      }

      async function chat(messages) {
        if (!isReady) throw new Error('LLM not ready');
        
        const response = await engine.chat.completions.create({
          messages: messages,
          temperature: parseFloat(config.temperature),
          max_tokens: parseInt(config.max_tokens),
          top_p: config.top_p
        });
        
        return response.choices[0].message.content;
      }

      return { initialize, chat, updateConfig, isReady: () => isReady };
    })();

    // ============================================
    // Main Application
    // ============================================
    const App = (() => {
      const state = {
        files: [],
        chatHistory: [],
        isEmbeddingReady: false,
        isLLMReady: false,
        isProcessing: false
      };

      const elements = {
        // ... (standard elements)
        dropZone: document.getElementById('dropZone'),
        fileInput: document.getElementById('fileInput'),
        totalVectors: document.getElementById('totalVectors'),
        memoryBank: document.getElementById('memoryBank'),
        chatContainer: document.getElementById('chatContainer'),
        chatInput: document.getElementById('chatInput'),
        sendBtn: document.getElementById('sendBtn'),
        clearBtn: document.getElementById('clearBtn'),
        embeddingStatus: document.getElementById('embeddingStatus'),
        llmStatus: document.getElementById('llmStatus'),
        processingStatus: document.getElementById('processingStatus'),
        inputHint: document.getElementById('inputHint'),
        
        // Control Elements
        tempSlider: document.getElementById('tempSlider'),
        tempValue: document.getElementById('tempValue'),
        tokenInput: document.getElementById('tokenInput'),
        modelSelect: document.getElementById('modelSelect'),
        currentModelDisplay: document.getElementById('currentModelDisplay')
      };

      const SYSTEM_PROMPT = `You are a precise Academic Research Assistant. 
Your goal is to answer the user's question based ONLY on the provided Context chunks.

Rules:
1. Use the provided Context to answer.
2. If the answer is not in the Context, state: "I cannot find information about this in the provided documents."
3. Cite the document names provided in the context when making claims.
4. Keep the tone professional and academic.`;

      async function init() {
        console.log('üìö Initializing Application...');
        
        // Controls Listeners
        setupControlListeners();

        await Promise.all([
          initializeEmbeddings(),
          initializeLLM(elements.modelSelect.value)
        ]);
        
        setupEventListeners();
        checkReadyState();
      }

      // ----------------------------------------
      // Control Logic
      // ----------------------------------------
      function setupControlListeners() {
        // Temperature Slider
        elements.tempSlider.addEventListener('input', (e) => {
          const val = e.target.value;
          elements.tempValue.textContent = val;
          LLMEngine.updateConfig({ temperature: val });
          updateSliderBackground(e.target);
        });

        // Max Tokens Input
        elements.tokenInput.addEventListener('change', (e) => {
          LLMEngine.updateConfig({ max_tokens: e.target.value });
        });

        // Model Selector
        elements.modelSelect.addEventListener('change', async (e) => {
          const modelId = e.target.value;
          const modelName = e.target.options[e.target.selectedIndex].text;
          
          if(confirm(`Switching to ${modelName} requires downloading the model. Continue?`)) {
            // Disable UI
            state.isLLMReady = false;
            elements.sendBtn.disabled = true;
            elements.chatInput.disabled = true;
            elements.currentModelDisplay.textContent = `Model: ${modelName}`;
            
            updateStatus(elements.llmStatus, 'Switching Model...', 'loading');
            
            try {
              await initializeLLM(modelId);
              checkReadyState();
            } catch(err) {
              alert("Failed to load model. Please refresh.");
            }
          } else {
            // Revert selection
            e.target.value = LLMEngine.currentModelId; 
          }
        });
      }

      function updateSliderBackground(slider) {
        const val = (slider.value - slider.min) / (slider.max - slider.min) * 100;
        slider.style.backgroundSize = val + '% 100%';
      }

      // ----------------------------------------
      // Initialization Logic
      // ----------------------------------------
      async function initializeEmbeddings() {
        try {
          await EmbeddingsEngine.initialize();
          state.isEmbeddingReady = true;
          updateStatus(elements.embeddingStatus, '‚úì Embeddings Ready', 'success');
        } catch (error) {
          updateStatus(elements.embeddingStatus, '‚úó Embeddings Failed', 'error');
        }
      }

      async function initializeLLM(modelId) {
        try {
          await LLMEngine.initialize(modelId, (progress) => {
            const percent = (progress.progress * 100).toFixed(0);
            updateStatus(elements.llmStatus, `Loading: ${percent}%`, 'loading');
            elements.inputHint.textContent = `Downloading AI Model (${percent}%)... please wait.`;
          });
          state.isLLMReady = true;
          updateStatus(elements.llmStatus, '‚úì LLM Ready', 'success');
          elements.inputHint.textContent = 'Ready to chat.';
        } catch (error) {
          updateStatus(elements.llmStatus, '‚úó LLM Failed', 'error');
        }
      }

      function updateStatus(element, text, type) {
        element.textContent = text;
        element.className = 'px-4 py-2 rounded-full text-sm font-semibold ';
        if (type === 'success') element.className += 'bg-green-500 text-white';
        else if (type === 'error') element.className += 'bg-red-500 text-white';
        else element.className += 'bg-yellow-400 text-gray-900';
      }

      function checkReadyState() {
        if (state.isEmbeddingReady && state.isLLMReady) {
          elements.chatInput.disabled = false;
          elements.sendBtn.disabled = false;
        }
      }

      function setupEventListeners() {
        elements.dropZone.addEventListener('click', () => elements.fileInput.click());
        elements.dropZone.addEventListener('dragover', (e) => {
          e.preventDefault();
          elements.dropZone.classList.add('bg-indigo-100');
        });
        elements.dropZone.addEventListener('dragleave', () => {
          elements.dropZone.classList.remove('bg-indigo-100');
        });
        elements.dropZone.addEventListener('drop', handleDrop);
        elements.fileInput.addEventListener('change', (e) => handleFiles(Array.from(e.target.files)));
        elements.sendBtn.addEventListener('click', handleSendMessage);
        elements.chatInput.addEventListener('keypress', (e) => {
          if (e.key === 'Enter' && !e.shiftKey) {
            e.preventDefault();
            handleSendMessage();
          }
        });
        elements.clearBtn.addEventListener('click', clearAllData);
      }

      function handleDrop(e) {
        e.preventDefault();
        elements.dropZone.classList.remove('bg-indigo-100');
        const files = Array.from(e.dataTransfer.files).filter(f => f.type === 'application/pdf');
        if (files.length > 0) handleFiles(files);
      }

      async function handleFiles(files) {
        if (!state.isEmbeddingReady) {
          alert('Please wait for embeddings to load');
          return;
        }

        state.isProcessing = true;

        for (const file of files) {
          if (state.files.some(f => f.name === file.name)) {
            alert(`File "${file.name}" is already loaded.`);
            continue;
          }
          await processAndEmbedFile(file);
        }

        state.isProcessing = false;
        updateUI();
      }

      async function processAndEmbedFile(file) {
        try {
          showProcessingStatus(`Processing ${file.name}...`, 0);
          const fileData = await PDFProcessor.processFile(file);
          
          showProcessingStatus(`Embedding ${file.name}...`, 0);
          const embeddings = await EmbeddingsEngine.generateBatchEmbeddings(
            fileData.chunks,
            (current, total) => {
              const progress = (current / total) * 100;
              showProcessingStatus(`Embedding ${file.name}: ${current}/${total}`, progress);
            }
          );

          const vectorEntries = fileData.chunks.map((chunk, idx) => ({
            text: chunk,
            embedding: embeddings[idx],
            source: file.name
          }));

          VectorStore.addVectors(vectorEntries);
          state.files.push(fileData);

          console.log(`‚úÖ Processed: ${file.name}`);
        } catch (error) {
          alert(`Error: ${error.message}`);
        }
      }

      function removeFile(fileName) {
        if(!confirm(`Are you sure you want to remove "${fileName}"?`)) return;
        VectorStore.removeVectorsBySource(fileName);
        state.files = state.files.filter(f => f.name !== fileName);
        updateUI();
      }

      function showProcessingStatus(message, progress) {
        elements.processingStatus.innerHTML = `
          <div class="mt-3 bg-indigo-50 rounded-lg p-3">
            <div class="text-sm text-indigo-700 mb-2">${message}</div>
            <div class="w-full bg-gray-200 rounded-full h-2">
              <div class="bg-indigo-600 h-2 rounded-full transition-all" style="width: ${progress}%"></div>
            </div>
          </div>
        `;
      }

      async function handleSendMessage() {
        const query = elements.chatInput.value.trim();
        if (!query || !state.isLLMReady) return;

        elements.chatInput.value = '';
        elements.sendBtn.disabled = true;

        addMessageToChat('user', query);

        try {
          let context = '';
          let citations = [];

          if (VectorStore.getStats().count > 0) {
            const queryEmbedding = await EmbeddingsEngine.generateEmbedding(query);
            const results = await VectorStore.search(queryEmbedding, 5);
            
            citations = results.map(r => ({
              source: r.source,
              text: r.text,
              similarity: r.similarity
            }));

            context = results.map((r, i) => 
              `[Document: ${r.source}]\n${r.text}`
            ).join('\n\n');
          }

          const messages = [
            { role: 'system', content: SYSTEM_PROMPT },
            ...state.chatHistory.slice(-6),
            { 
              role: 'user', 
              content: context ? 
                `Context:\n${context}\n\nQuestion: ${query}` : 
                query 
            }
          ];

          const response = await LLMEngine.chat(messages);

          state.chatHistory.push(
            { role: 'user', content: query },
            { role: 'assistant', content: response }
          );

          addMessageToChat('assistant', response, citations);

        } catch (error) {
          addMessageToChat('error', `Error: ${error.message}`);
        } finally {
          elements.sendBtn.disabled = false;
          elements.chatInput.focus();
        }
      }

      function addMessageToChat(role, content, citations = []) {
        const messageDiv = document.createElement('div');
        messageDiv.className = 'chat-message';

        if (role === 'user') {
          messageDiv.innerHTML = `
            <div class="flex justify-end mb-4">
              <div class="bg-indigo-600 text-white rounded-lg px-4 py-3 max-w-md">
                ${escapeHtml(content)}
              </div>
            </div>
          `;
        } else if (role === 'assistant') {
          let citationsHtml = '';
          const uniqueSources = [...new Set(citations.map(c => c.source))];
          
          if (uniqueSources.length > 0) {
            citationsHtml = `
              <div class="mt-3 pt-2 border-t border-gray-200">
                <div class="text-xs text-gray-500 mb-1 font-semibold">üìö Sources Used:</div>
                <div class="flex flex-wrap gap-2">
                  ${uniqueSources.map(source => `
                    <span class="text-xs bg-indigo-50 text-indigo-700 px-2 py-1 rounded border border-indigo-100">
                      üìÑ ${escapeHtml(source)}
                    </span>
                  `).join('')}
                </div>
              </div>
            `;
          }

          messageDiv.innerHTML = `
            <div class="flex justify-start mb-4">
              <div class="bg-white border border-gray-200 rounded-lg px-4 py-3 max-w-md shadow-sm">
                <div class="flex items-start gap-3">
                  <span class="text-2xl mt-1">ü§ñ</span>
                  <div class="flex-1 overflow-hidden">
                    <div class="text-gray-800 prose prose-sm max-w-none">
                      ${marked.parse(content)}
                    </div>
                    ${citationsHtml}
                  </div>
                </div>
              </div>
            </div>
          `;
        } else {
          messageDiv.innerHTML = `
            <div class="flex justify-center mb-4">
              <div class="bg-red-100 text-red-700 rounded-lg px-4 py-3 text-sm">
                ${escapeHtml(content)}
              </div>
            </div>
          `;
        }

        elements.chatContainer.appendChild(messageDiv);
        elements.chatContainer.scrollTop = elements.chatContainer.scrollHeight;
      }

      function updateUI() {
        const stats = VectorStore.getStats();
        elements.totalVectors.textContent = `${stats.count} Vectors`;

        if (state.files.length > 0) {
          elements.memoryBank.innerHTML = `
            <div class="space-y-2 max-h-[300px] overflow-y-auto pr-2">
              ${state.files.map(file => `
                <div class="file-item flex justify-between items-center bg-white/10 p-3 rounded-lg border border-white/10">
                  <div class="flex items-center gap-3 overflow-hidden">
                    <span class="text-xl">üìÑ</span>
                    <div class="flex flex-col overflow-hidden">
                      <span class="text-sm font-medium truncate" title="${file.name}">${file.name}</span>
                      <span class="text-xs opacity-70">${file.chunkCount} chunks</span>
                    </div>
                  </div>
                  <button onclick="window.removeFile('${file.name}')" class="text-red-300 hover:text-red-100 hover:bg-red-500/20 p-2 rounded-full transition-all" title="Delete file">
                    <i class="fas fa-trash-alt"></i>
                  </button>
                </div>
              `).join('')}
            </div>
          `;
        } else {
           elements.memoryBank.innerHTML = `
            <div class="text-center opacity-80 text-sm italic mt-8">No documents loaded</div>
          `;
        }

        elements.processingStatus.innerHTML = '';
      }

      function clearAllData() {
        if (confirm('Clear all data and chat history?')) {
          VectorStore.clear();
          state.files = [];
          state.chatHistory = [];
          elements.chatContainer.innerHTML = `
            <div class="text-center text-gray-500 py-8">
              <div class="text-4xl mb-2">ü§ñ</div>
              <p>Upload PDFs and start chatting!</p>
            </div>
          `;
          updateUI();
        }
      }

      function escapeHtml(text) {
        if (!text) return '';
        const div = document.createElement('div');
        div.textContent = text;
        return div.innerHTML;
      }

      window.removeFile = removeFile;

      return { init };
    })();

    const marked = {
      parse: (text) => {
        text = text.replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>');
        text = text.replace(/\*(.*?)\*/g, '<em>$1</em>');
        text = text.replace(/```([\s\S]*?)```/g, '<pre class="bg-gray-100 p-2 rounded text-xs overflow-x-auto">$1</pre>');
        text = text.replace(/`([^`]+)`/g, '<code class="bg-gray-100 px-1 rounded text-sm">$1</code>');
        text = text.replace(/\n/g, '<br>');
        return text;
      }
    };

    App.init();
  </script>
</body>
</html>